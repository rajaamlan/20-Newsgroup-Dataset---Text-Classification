{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages and Libraries we used in the Project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training and test data\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data_test = fetch_20newsgroups(subset='test', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing out all the categories\n",
    "\n",
    "data_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 11314\n"
     ]
    }
   ],
   "source": [
    "## Total Number of Documents\n",
    "print('Number of documents:', len(data_train.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bag of words - Implementation of CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### using TF - IDF Vectorizer here, comments mentioned in the report\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Multinomial Naive Bayes Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### NAIVE BAYES MODEL ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Naive Bayes Model on training data set\n",
    "\n",
    "NB = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "NB = NB.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier on training data set: 0.9326498143892522\n"
     ]
    }
   ],
   "source": [
    "#Performance of NB model on training data set\n",
    "\n",
    "predicted = NB.predict(data_train.data)\n",
    "acc = np.mean(predicted == data_train.target)\n",
    "print('Accuracy of Naive Bayes Classifier on training data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.83      0.87       480\n",
      "           comp.graphics       0.98      0.93      0.95       584\n",
      " comp.os.ms-windows.misc       0.97      0.95      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.90      0.96      0.93       590\n",
      "   comp.sys.mac.hardware       0.99      0.97      0.98       578\n",
      "          comp.windows.x       0.99      0.96      0.97       593\n",
      "            misc.forsale       0.97      0.86      0.91       585\n",
      "               rec.autos       0.96      0.99      0.97       594\n",
      "         rec.motorcycles       0.99      0.98      0.99       598\n",
      "      rec.sport.baseball       0.99      0.98      0.99       597\n",
      "        rec.sport.hockey       0.97      0.99      0.98       600\n",
      "               sci.crypt       0.89      0.99      0.94       595\n",
      "         sci.electronics       0.98      0.94      0.96       591\n",
      "                 sci.med       1.00      0.96      0.98       594\n",
      "               sci.space       0.96      0.99      0.98       593\n",
      "  soc.religion.christian       0.63      1.00      0.77       599\n",
      "      talk.politics.guns       0.89      0.99      0.94       546\n",
      "   talk.politics.mideast       0.97      0.98      0.97       564\n",
      "      talk.politics.misc       0.99      0.83      0.90       465\n",
      "      talk.religion.misc       0.99      0.29      0.45       377\n",
      "\n",
      "             avg / total       0.94      0.93      0.93     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Classification Report for Various Categories\n",
    "\n",
    "print(classification_report(data_train.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier on test data set: 0.7738980350504514\n"
     ]
    }
   ],
   "source": [
    "##### Performance of model on test data set\n",
    "\n",
    "predicted = NB.predict(data_test.data)\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print('Accuracy of Naive Bayes Classifier on test data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "             avg / total       0.82      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Classification Report #####\n",
    "print(classification_report(data_test.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "# Here, we are creating a list of parameters for which we would like to do performance tuning. \n",
    "# E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_clf = GridSearchCV(NB, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB with Grid Search: 0.7738980350504514\n"
     ]
    }
   ],
   "source": [
    "#### Accuracy of Naive Bayes With Grid Search with Train Data\n",
    "print('Accuracy of NB with Grid Search:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB with Grid search on test data: 0.8344397238449283\n"
     ]
    }
   ],
   "source": [
    "### Accuracy of Naive Bayes with Grid Search for Test Data\n",
    "predicted = gs_clf.predict(data_test.data)\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print('Accuracy of NB with Grid search on test data:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters for performance tuning: {'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "###### Best Parameters ####\n",
    "print('best parameters for performance tuning:',gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words and implementing NB model\n",
    "\n",
    "NB = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('nb', MultinomialNB())])\n",
    "\n",
    "NB = NB.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier on training data set: 0.9573979140887396\n"
     ]
    }
   ],
   "source": [
    "# performance of NB model on training set after removing stop words\n",
    "\n",
    "predicted = NB.predict(data_train.data)\n",
    "acc = np.mean(predicted == data_train.target)\n",
    "print('Accuracy of Naive Bayes Classifier on training data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.94      0.93       480\n",
      "           comp.graphics       0.98      0.95      0.97       584\n",
      " comp.os.ms-windows.misc       0.96      0.96      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.91      0.96      0.94       590\n",
      "   comp.sys.mac.hardware       0.98      0.98      0.98       578\n",
      "          comp.windows.x       0.98      0.98      0.98       593\n",
      "            misc.forsale       0.97      0.93      0.95       585\n",
      "               rec.autos       0.97      0.98      0.98       594\n",
      "         rec.motorcycles       0.98      0.99      0.99       598\n",
      "      rec.sport.baseball       0.98      0.99      0.99       597\n",
      "        rec.sport.hockey       0.97      1.00      0.98       600\n",
      "               sci.crypt       0.98      0.99      0.98       595\n",
      "         sci.electronics       0.98      0.96      0.97       591\n",
      "                 sci.med       0.99      0.98      0.98       594\n",
      "               sci.space       0.97      1.00      0.98       593\n",
      "  soc.religion.christian       0.80      1.00      0.89       599\n",
      "      talk.politics.guns       0.93      0.99      0.96       546\n",
      "   talk.politics.mideast       0.97      0.99      0.98       564\n",
      "      talk.politics.misc       0.99      0.92      0.95       465\n",
      "      talk.religion.misc       0.99      0.49      0.65       377\n",
      "\n",
      "             avg / total       0.96      0.96      0.96     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Classification Report for Above model\n",
    "print(classification_report(data_train.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier on test data set: 0.8169144981412639\n"
     ]
    }
   ],
   "source": [
    "# Performance of NB model on test data after removing stop words\n",
    "\n",
    "predicted = NB.predict(data_test.data)\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print('Accuracy of Naive Bayes Classifier on test data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.69      0.74       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.79      0.72      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.68      0.81      0.74       392\n",
      "   comp.sys.mac.hardware       0.86      0.81      0.84       385\n",
      "          comp.windows.x       0.87      0.78      0.82       395\n",
      "            misc.forsale       0.87      0.80      0.83       390\n",
      "               rec.autos       0.88      0.91      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.91      0.92      0.92       397\n",
      "        rec.sport.hockey       0.88      0.98      0.93       399\n",
      "               sci.crypt       0.75      0.96      0.84       396\n",
      "         sci.electronics       0.84      0.65      0.74       393\n",
      "                 sci.med       0.92      0.79      0.85       396\n",
      "               sci.space       0.82      0.94      0.88       394\n",
      "  soc.religion.christian       0.62      0.96      0.76       398\n",
      "      talk.politics.guns       0.66      0.95      0.78       364\n",
      "   talk.politics.mideast       0.95      0.94      0.94       376\n",
      "      talk.politics.misc       0.94      0.52      0.67       310\n",
      "      talk.religion.misc       0.95      0.24      0.38       251\n",
      "\n",
      "             avg / total       0.83      0.82      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Classification Report for Above Model\n",
    "print(classification_report(data_test.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the parameter of NB model\n",
    "# Setting FitPrior as False\n",
    "\n",
    "NB = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('nb', MultinomialNB(fit_prior=False))])\n",
    "\n",
    "NB = NB.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier on training data set: 0.9627894643804137\n"
     ]
    }
   ],
   "source": [
    "# Performance of NB model on training set after changing the model's parameter\n",
    "\n",
    "predicted = NB.predict(data_train.data)\n",
    "acc = np.mean(predicted == data_train.target)\n",
    "print('Accuracy of Naive Bayes Classifier on training data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.96      0.94       480\n",
      "           comp.graphics       0.98      0.95      0.97       584\n",
      " comp.os.ms-windows.misc       0.96      0.96      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.91      0.96      0.94       590\n",
      "   comp.sys.mac.hardware       0.98      0.98      0.98       578\n",
      "          comp.windows.x       0.99      0.98      0.98       593\n",
      "            misc.forsale       0.97      0.93      0.95       585\n",
      "               rec.autos       0.97      0.98      0.98       594\n",
      "         rec.motorcycles       0.99      0.99      0.99       598\n",
      "      rec.sport.baseball       0.99      0.99      0.99       597\n",
      "        rec.sport.hockey       0.98      0.99      0.99       600\n",
      "               sci.crypt       0.98      0.99      0.99       595\n",
      "         sci.electronics       0.98      0.96      0.97       591\n",
      "                 sci.med       0.99      0.98      0.99       594\n",
      "               sci.space       0.98      1.00      0.99       593\n",
      "  soc.religion.christian       0.85      1.00      0.91       599\n",
      "      talk.politics.guns       0.94      0.99      0.97       546\n",
      "   talk.politics.mideast       0.98      1.00      0.99       564\n",
      "      talk.politics.misc       0.98      0.94      0.96       465\n",
      "      talk.religion.misc       1.00      0.59      0.74       377\n",
      "\n",
      "             avg / total       0.96      0.96      0.96     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier on test data set: 0.8214285714285714\n"
     ]
    }
   ],
   "source": [
    "# Performance of NB model on test data after changing the model's parameter\n",
    "\n",
    "predicted = NB.predict(data_test.data)\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print('Accuracy of Naive Bayes Classifier on test data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.71      0.75       319\n",
      "           comp.graphics       0.77      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.79      0.72      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.69      0.80      0.74       392\n",
      "   comp.sys.mac.hardware       0.86      0.82      0.84       385\n",
      "          comp.windows.x       0.87      0.78      0.82       395\n",
      "            misc.forsale       0.87      0.80      0.83       390\n",
      "               rec.autos       0.89      0.91      0.90       396\n",
      "         rec.motorcycles       0.94      0.96      0.95       398\n",
      "      rec.sport.baseball       0.91      0.92      0.92       397\n",
      "        rec.sport.hockey       0.88      0.98      0.93       399\n",
      "               sci.crypt       0.76      0.96      0.85       396\n",
      "         sci.electronics       0.85      0.65      0.73       393\n",
      "                 sci.med       0.93      0.78      0.85       396\n",
      "               sci.space       0.83      0.94      0.88       394\n",
      "  soc.religion.christian       0.66      0.95      0.78       398\n",
      "      talk.politics.guns       0.67      0.95      0.79       364\n",
      "   talk.politics.mideast       0.94      0.94      0.94       376\n",
      "      talk.politics.misc       0.90      0.54      0.68       310\n",
      "      talk.religion.misc       0.91      0.32      0.47       251\n",
      "\n",
      "             avg / total       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Raja\n",
      "[nltk_data]     Amlan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming and Implementing NB model\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('mnb', MultinomialNB(fit_prior=False))])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(data_train.data, data_train.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9554534205409227\n"
     ]
    }
   ],
   "source": [
    "# Performance of NB model on training set after stemming\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(data_train.data)\n",
    "\n",
    "acc = np.mean(predicted_mnb_stemmed == data_train.target)\n",
    "print('Accuracy is:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.94      0.93       480\n",
      "           comp.graphics       0.98      0.94      0.96       584\n",
      " comp.os.ms-windows.misc       0.96      0.96      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.90      0.96      0.93       590\n",
      "   comp.sys.mac.hardware       0.97      0.97      0.97       578\n",
      "          comp.windows.x       0.98      0.97      0.98       593\n",
      "            misc.forsale       0.96      0.90      0.93       585\n",
      "               rec.autos       0.97      0.98      0.97       594\n",
      "         rec.motorcycles       0.99      0.98      0.99       598\n",
      "      rec.sport.baseball       0.99      0.99      0.99       597\n",
      "        rec.sport.hockey       0.97      0.99      0.98       600\n",
      "               sci.crypt       0.96      0.99      0.97       595\n",
      "         sci.electronics       0.97      0.95      0.96       591\n",
      "                 sci.med       1.00      0.98      0.99       594\n",
      "               sci.space       0.97      1.00      0.99       593\n",
      "  soc.religion.christian       0.82      0.99      0.90       599\n",
      "      talk.politics.guns       0.92      0.99      0.96       546\n",
      "   talk.politics.mideast       0.97      0.99      0.98       564\n",
      "      talk.politics.misc       0.98      0.93      0.95       465\n",
      "      talk.religion.misc       1.00      0.54      0.70       377\n",
      "\n",
      "             avg / total       0.96      0.96      0.95     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train.target, predicted_mnb_stemmed, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8167817312798725\n"
     ]
    }
   ],
   "source": [
    "# Performance of NB model on test data set after stemming\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(data_test.data)\n",
    "\n",
    "acc = np.mean(predicted_mnb_stemmed == data_test.target)\n",
    "print('Accuracy is:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.70      0.75       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.82      0.69      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.69      0.79      0.74       392\n",
      "   comp.sys.mac.hardware       0.85      0.83      0.84       385\n",
      "          comp.windows.x       0.86      0.79      0.83       395\n",
      "            misc.forsale       0.88      0.75      0.81       390\n",
      "               rec.autos       0.88      0.92      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.94       398\n",
      "      rec.sport.baseball       0.93      0.92      0.92       397\n",
      "        rec.sport.hockey       0.91      0.98      0.94       399\n",
      "               sci.crypt       0.72      0.97      0.83       396\n",
      "         sci.electronics       0.83      0.64      0.72       393\n",
      "                 sci.med       0.92      0.78      0.84       396\n",
      "               sci.space       0.83      0.94      0.88       394\n",
      "  soc.religion.christian       0.64      0.96      0.77       398\n",
      "      talk.politics.guns       0.65      0.95      0.77       364\n",
      "   talk.politics.mideast       0.93      0.95      0.94       376\n",
      "      talk.politics.misc       0.90      0.54      0.67       310\n",
      "      talk.religion.misc       0.93      0.29      0.45       251\n",
      "\n",
      "             avg / total       0.83      0.82      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test.target, predicted_mnb_stemmed, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">SVM Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# SVM Model ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raja Amlan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM model on training data: 0.966590065405692\n"
     ]
    }
   ],
   "source": [
    "## Building SVM model on training data set and evalutaing its performance on the basis of accuracy\n",
    "\n",
    "svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "svm = svm.fit(data_train.data, data_train.target)\n",
    "predict = svm.predict(data_train.data)\n",
    "acc = np.mean(predict == data_train.target)\n",
    "print('Accuracy of SVM model on training data:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.95      0.96      0.95       480\n",
      "           comp.graphics       0.98      0.94      0.96       584\n",
      " comp.os.ms-windows.misc       0.95      0.97      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.94      0.94      0.94       590\n",
      "   comp.sys.mac.hardware       0.99      0.97      0.98       578\n",
      "          comp.windows.x       0.98      0.97      0.98       593\n",
      "            misc.forsale       0.92      0.96      0.94       585\n",
      "               rec.autos       0.98      0.98      0.98       594\n",
      "         rec.motorcycles       0.98      0.99      0.99       598\n",
      "      rec.sport.baseball       1.00      0.98      0.99       597\n",
      "        rec.sport.hockey       0.97      1.00      0.98       600\n",
      "               sci.crypt       0.98      1.00      0.99       595\n",
      "         sci.electronics       0.99      0.94      0.97       591\n",
      "                 sci.med       0.99      0.99      0.99       594\n",
      "               sci.space       0.97      1.00      0.98       593\n",
      "  soc.religion.christian       0.88      0.99      0.93       599\n",
      "      talk.politics.guns       0.96      0.99      0.98       546\n",
      "   talk.politics.mideast       0.97      1.00      0.98       564\n",
      "      talk.politics.misc       0.99      0.95      0.97       465\n",
      "      talk.religion.misc       0.99      0.73      0.84       377\n",
      "\n",
      "             avg / total       0.97      0.97      0.97     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train.target, predict, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM model on test data: 0.8238183749336165\n"
     ]
    }
   ],
   "source": [
    "# Performance of SVM Model on test data\n",
    "\n",
    "predict = svm.predict(data_test.data)\n",
    "acc = np.mean(predict == data_test.target)\n",
    "print('Accuracy of SVM model on test data:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.72      0.72       319\n",
      "           comp.graphics       0.80      0.70      0.74       389\n",
      " comp.os.ms-windows.misc       0.73      0.76      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.70      0.70       392\n",
      "   comp.sys.mac.hardware       0.83      0.81      0.82       385\n",
      "          comp.windows.x       0.83      0.77      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.92      0.89      0.91       396\n",
      "         rec.motorcycles       0.92      0.96      0.94       398\n",
      "      rec.sport.baseball       0.89      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.83      0.96      0.89       396\n",
      "         sci.electronics       0.83      0.60      0.70       393\n",
      "                 sci.med       0.87      0.86      0.86       396\n",
      "               sci.space       0.84      0.96      0.89       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.40      0.55       251\n",
      "\n",
      "             avg / total       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test.target, predict, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raja Amlan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM Model with Grid Search: 0.8979140887396146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Similarly doing grid search for SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "gs_clf_svm = GridSearchCV(svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(data_train.data, data_train.target)\n",
    "\n",
    "### Accuracy of this model with Training Data\n",
    "\n",
    "acc = gs_clf_svm.best_score_\n",
    "print('Accuracy of SVM Model with Grid Search:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM with Grid Search on test data: 0.8331120552310144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Accuracy of this model with Test Data.\n",
    "\n",
    "predicted = gs_clf_svm.predict(data_test.data)\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print('Accuracy of SVM with Grid Search on test data:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters for svm model: {'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "### Best Parameters for this model.\n",
    "\n",
    "print('best parameters for svm model:', gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raja Amlan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM model on training data: 0.9661481350539155\n"
     ]
    }
   ],
   "source": [
    "# Building SVM model after removing stop words on training data set\n",
    "\n",
    "svm = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()),\n",
    "                ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "svm = svm.fit(data_train.data, data_train.target)\n",
    "predict = svm.predict(data_train.data)\n",
    "acc = np.mean(predict == data_train.target)\n",
    "print('Accuracy of SVM model on training data:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.94      0.95      0.95       480\n",
      "           comp.graphics       0.99      0.95      0.97       584\n",
      " comp.os.ms-windows.misc       0.95      0.97      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.94      0.94      0.94       590\n",
      "   comp.sys.mac.hardware       0.99      0.97      0.98       578\n",
      "          comp.windows.x       0.98      0.97      0.98       593\n",
      "            misc.forsale       0.93      0.95      0.94       585\n",
      "               rec.autos       0.97      0.98      0.97       594\n",
      "         rec.motorcycles       0.99      0.99      0.99       598\n",
      "      rec.sport.baseball       0.99      0.98      0.99       597\n",
      "        rec.sport.hockey       0.97      0.99      0.98       600\n",
      "               sci.crypt       0.98      1.00      0.99       595\n",
      "         sci.electronics       0.99      0.94      0.96       591\n",
      "                 sci.med       0.99      0.99      0.99       594\n",
      "               sci.space       0.97      0.99      0.98       593\n",
      "  soc.religion.christian       0.88      0.99      0.93       599\n",
      "      talk.politics.guns       0.96      0.99      0.97       546\n",
      "   talk.politics.mideast       0.98      1.00      0.99       564\n",
      "      talk.politics.misc       0.99      0.95      0.97       465\n",
      "      talk.religion.misc       0.98      0.72      0.83       377\n",
      "\n",
      "             avg / total       0.97      0.97      0.97     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train.target, predict, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM model on test data: 0.8224907063197026\n"
     ]
    }
   ],
   "source": [
    "# Performance of SVM Model on test data after removing stop words\n",
    "\n",
    "predict = svm.predict(data_test.data)\n",
    "acc = np.mean(predict == data_test.target)\n",
    "print('Accuracy of SVM model on test data:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.71      0.71       319\n",
      "           comp.graphics       0.79      0.70      0.74       389\n",
      " comp.os.ms-windows.misc       0.73      0.77      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.68      0.69       392\n",
      "   comp.sys.mac.hardware       0.82      0.82      0.82       385\n",
      "          comp.windows.x       0.84      0.77      0.80       395\n",
      "            misc.forsale       0.82      0.87      0.85       390\n",
      "               rec.autos       0.91      0.89      0.90       396\n",
      "         rec.motorcycles       0.92      0.97      0.94       398\n",
      "      rec.sport.baseball       0.90      0.91      0.90       397\n",
      "        rec.sport.hockey       0.86      0.98      0.92       399\n",
      "               sci.crypt       0.85      0.96      0.90       396\n",
      "         sci.electronics       0.81      0.62      0.70       393\n",
      "                 sci.med       0.90      0.87      0.88       396\n",
      "               sci.space       0.83      0.96      0.89       394\n",
      "  soc.religion.christian       0.74      0.93      0.82       398\n",
      "      talk.politics.guns       0.70      0.93      0.80       364\n",
      "   talk.politics.mideast       0.92      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.56      0.69       310\n",
      "      talk.religion.misc       0.82      0.39      0.53       251\n",
      "\n",
      "             avg / total       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test.target, predict, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raja Amlan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Stemming and implementing SVM model\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_svm_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()),('svm', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "text_svm_stemmed = text_svm_stemmed.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9593424076365564\n"
     ]
    }
   ],
   "source": [
    "# Performance of SVM model on training set after stemming\n",
    "\n",
    "predicted_svm_stemmed = text_svm_stemmed.predict(data_train.data)\n",
    "\n",
    "acc = np.mean(predicted_svm_stemmed == data_train.target)\n",
    "print('Accuracy is:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8194370685077005\n"
     ]
    }
   ],
   "source": [
    "# Performance of SVM model on test data set after stemming\n",
    "\n",
    "predicted_svm_stemmed = text_svm_stemmed.predict(data_test.data)\n",
    "\n",
    "acc = np.mean(predicted_svm_stemmed == data_test.target)\n",
    "print('Accuracy is:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Logistic Regression Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Logistic Regression Model ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Logistic Regression Model on training data set\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('lr', LogisticRegression(random_state=0))])\n",
    "\n",
    "pipe = pipe.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model on training data set: 0.9698603500088386\n"
     ]
    }
   ],
   "source": [
    "#Performance of Logistic regression model on training data set\n",
    "\n",
    "predicted = pipe.predict(data_train.data)\n",
    "acc = np.mean(predicted == data_train.target)\n",
    "print('Accuracy of Logistic Regression Model on training data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.97      0.97      0.97       480\n",
      "           comp.graphics       0.93      0.96      0.95       584\n",
      " comp.os.ms-windows.misc       0.95      0.97      0.96       591\n",
      "comp.sys.ibm.pc.hardware       0.93      0.94      0.94       590\n",
      "   comp.sys.mac.hardware       0.99      0.97      0.98       578\n",
      "          comp.windows.x       0.98      0.97      0.98       593\n",
      "            misc.forsale       0.90      0.95      0.93       585\n",
      "               rec.autos       0.98      0.97      0.97       594\n",
      "         rec.motorcycles       1.00      0.99      0.99       598\n",
      "      rec.sport.baseball       0.99      0.99      0.99       597\n",
      "        rec.sport.hockey       0.99      0.99      0.99       600\n",
      "               sci.crypt       0.99      0.98      0.99       595\n",
      "         sci.electronics       0.97      0.97      0.97       591\n",
      "                 sci.med       0.99      0.98      0.99       594\n",
      "               sci.space       0.98      0.99      0.99       593\n",
      "  soc.religion.christian       0.93      0.98      0.96       599\n",
      "      talk.politics.guns       0.97      0.99      0.98       546\n",
      "   talk.politics.mideast       0.98      0.99      0.99       564\n",
      "      talk.politics.misc       0.99      0.95      0.97       465\n",
      "      talk.religion.misc       0.98      0.83      0.90       377\n",
      "\n",
      "             avg / total       0.97      0.97      0.97     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model on test data set: 0.8279341476367499\n"
     ]
    }
   ],
   "source": [
    "### Performance of Log. Regression on Test Data\n",
    "predicted = pipe.predict(data_test.data)\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print('Accuracy of Logistic Regression Model on test data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.74      0.77       319\n",
      "           comp.graphics       0.69      0.78      0.74       389\n",
      " comp.os.ms-windows.misc       0.76      0.75      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.72      0.72       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.83      0.74      0.78       395\n",
      "            misc.forsale       0.76      0.90      0.83       390\n",
      "               rec.autos       0.91      0.89      0.90       396\n",
      "         rec.motorcycles       0.94      0.95      0.94       398\n",
      "      rec.sport.baseball       0.87      0.93      0.90       397\n",
      "        rec.sport.hockey       0.94      0.96      0.95       399\n",
      "               sci.crypt       0.93      0.89      0.91       396\n",
      "         sci.electronics       0.76      0.78      0.77       393\n",
      "                 sci.med       0.89      0.84      0.86       396\n",
      "               sci.space       0.89      0.92      0.91       394\n",
      "  soc.religion.christian       0.79      0.93      0.85       398\n",
      "      talk.politics.guns       0.71      0.90      0.80       364\n",
      "   talk.politics.mideast       0.96      0.89      0.92       376\n",
      "      talk.politics.misc       0.79      0.58      0.67       310\n",
      "      talk.religion.misc       0.83      0.45      0.59       251\n",
      "\n",
      "             avg / total       0.83      0.83      0.83      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Logistic Regression Model on training data set after removing stop words\n",
    "\n",
    "LR = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('lr', LogisticRegression())])\n",
    "\n",
    "LR = LR.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model on training data set: 0.9746331978080255\n"
     ]
    }
   ],
   "source": [
    "# Evaluating performance of Logistic regression model on training set after removing stop word\n",
    "predicted = LR.predict(data_train.data)\n",
    "acc = np.mean(predicted == data_train.target)\n",
    "print('Accuracy of Logistic Regression Model on training data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model on test data set: 0.8297928836962294\n"
     ]
    }
   ],
   "source": [
    "# Evaluating performance of Logistic regression model on training set after removing stop word\n",
    "predicted = LR.predict(data_test.data)\n",
    "acc = np.mean(predicted == data_test.target)\n",
    "print('Accuracy of Logistic Regression Model on test data set:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.78      0.72      0.75       319\n",
      "           comp.graphics       0.71      0.79      0.75       389\n",
      " comp.os.ms-windows.misc       0.75      0.76      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.71      0.71       392\n",
      "   comp.sys.mac.hardware       0.80      0.82      0.81       385\n",
      "          comp.windows.x       0.84      0.75      0.79       395\n",
      "            misc.forsale       0.78      0.87      0.82       390\n",
      "               rec.autos       0.90      0.89      0.89       396\n",
      "         rec.motorcycles       0.93      0.95      0.94       398\n",
      "      rec.sport.baseball       0.88      0.92      0.90       397\n",
      "        rec.sport.hockey       0.93      0.96      0.94       399\n",
      "               sci.crypt       0.95      0.91      0.93       396\n",
      "         sci.electronics       0.74      0.78      0.76       393\n",
      "                 sci.med       0.88      0.86      0.87       396\n",
      "               sci.space       0.88      0.91      0.90       394\n",
      "  soc.religion.christian       0.80      0.93      0.86       398\n",
      "      talk.politics.guns       0.74      0.90      0.81       364\n",
      "   talk.politics.mideast       0.97      0.89      0.93       376\n",
      "      talk.politics.misc       0.85      0.58      0.69       310\n",
      "      talk.religion.misc       0.81      0.49      0.61       251\n",
      "\n",
      "             avg / total       0.83      0.83      0.83      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test.target, predicted, target_names=data_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LR model after stemming on train set: 0.969948736079194\n",
      "Accuracy of LR model after stemming on test set: 0.8321826872012745\n"
     ]
    }
   ],
   "source": [
    "# Stemming and building Logistic regression model on training set and predicting the accuracy for the model on training and test data sets\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('mnb', LogisticRegression())])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(data_train.data, data_train.target)\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(data_train.data)\n",
    "\n",
    "acc = np.mean(predicted_mnb_stemmed == data_train.target)\n",
    "\n",
    "# Evaluating performance of LR model on test data\n",
    "predicted_mnb_stemmed2 = text_mnb_stemmed.predict(data_test.data)\n",
    "\n",
    "acc2 = np.mean(predicted_mnb_stemmed2 == data_test.target)\n",
    "print('Accuracy of LR model after stemming on train set:', acc)\n",
    "print('Accuracy of LR model after stemming on test set:', acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.77      0.71      0.74       319\n",
      "           comp.graphics       0.72      0.80      0.76       389\n",
      " comp.os.ms-windows.misc       0.76      0.76      0.76       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.73      0.73       392\n",
      "   comp.sys.mac.hardware       0.80      0.84      0.82       385\n",
      "          comp.windows.x       0.84      0.77      0.81       395\n",
      "            misc.forsale       0.75      0.85      0.80       390\n",
      "               rec.autos       0.91      0.88      0.90       396\n",
      "         rec.motorcycles       0.97      0.95      0.96       398\n",
      "      rec.sport.baseball       0.91      0.92      0.92       397\n",
      "        rec.sport.hockey       0.93      0.97      0.95       399\n",
      "               sci.crypt       0.94      0.92      0.93       396\n",
      "         sci.electronics       0.75      0.78      0.77       393\n",
      "                 sci.med       0.88      0.86      0.87       396\n",
      "               sci.space       0.88      0.93      0.90       394\n",
      "  soc.religion.christian       0.80      0.91      0.85       398\n",
      "      talk.politics.guns       0.73      0.90      0.81       364\n",
      "   talk.politics.mideast       0.97      0.88      0.92       376\n",
      "      talk.politics.misc       0.83      0.60      0.69       310\n",
      "      talk.religion.misc       0.80      0.47      0.59       251\n",
      "\n",
      "               micro avg       0.83      0.83      0.83      7532\n",
      "               macro avg       0.83      0.82      0.82      7532\n",
      "            weighted avg       0.83      0.83      0.83      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Classification report for the categories ###\n",
    "print(classification_report(data_test.target, predicted_mnb_stemmed2, target_names=data_train.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
